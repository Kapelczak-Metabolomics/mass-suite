{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster,mixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "from pandas.core.common import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "blank removal --> noise removal --> find unique/shared clusters --> use information for id --> use information for tracking\n",
    "```\n",
    "sudo code:\n",
    "picking up sources\n",
    "output labeled table\n",
    "use the information for the source id\n",
    "\n",
    "two way:\n",
    "1. venn diagram --> source id\n",
    "2. more data: single source approach to identify clusters for different sources and use the modeling approach for source tracking\n",
    "```\n",
    "\n",
    "important : tweak the parameters during venn diagram approach\n",
    "\n",
    "Two ways: use source data + venn diagram, give unique cluster higher score and shared cluster lower score, given a new sample, can predict the source id, or assign with possibility scores, for instance >70% of cluster features present then the shource exists. Hard to do source tracking since matrix effect and dilution effect is not considered\n",
    "\n",
    "better way with more data: every source with dilution series, and use the single source approach to find clusters, and modeling for the source approportioning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = pd.read_csv('../example_data/clustering/sample1114.csv')\n",
    "d_ms = d_ms.rename(columns={'Average Rt(min)': 'Average RT (min)', 'Average Mz': 'Average m/z', 'S/N average': 'Average sn'})\n",
    "d_ms.insert(3, \"Average score\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(d_input, blank_keyword, svb_thres=10, empty_thres=0, cv_thres=3,rt_range=[0, 30], mz_range=[0, 1200], sn_thres=3, score_thres=0, area_thres=5000):\n",
    "    '''\n",
    "    The function is used to clean the dataframe according to user setting\n",
    "    blank_keyword: part of string from column that indicates the column is a blank sample\n",
    "    svb_thres: sample vs blank thres\n",
    "    empty_thres: empty cell thres in a row\n",
    "    cv_thres: as all sample is in triplicate, calculate the CV for every triplicate sample set #Needs to be updated in case there is no triplicate samples\n",
    "    rt_range: rt filter\n",
    "    mz_range: mz filter\n",
    "    sn_thres: signal/noise column thres\n",
    "    score_thres: score column thres\n",
    "    area_thres: count for max peak area from each row\n",
    "    '''\n",
    "    d_thres = d_input[d_input[d_input.columns[4:]].max(1) >= area_thres]\n",
    "    \n",
    "    d_thres = d_thres[(d_thres['Average RT (min)'] > rt_range[0]) & (d_thres['Average RT (min)'] < rt_range[1])]\n",
    "    d_thres = d_thres[(d_thres['Average m/z'] > mz_range[0]) & (d_thres['Average m/z'] < mz_range[1])]\n",
    "    d_thres = d_thres[d_thres['Average sn'] >= sn_thres]\n",
    "    d_thres = d_thres[d_thres['Average score'] >= score_thres]\n",
    "    d_thres.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    col_blank = []\n",
    "    for key in blank_keyword:\n",
    "        # Get column name if it contains blank indicating strings\n",
    "        col_blank.extend([col for col in d_thres.columns if key in col])\n",
    "        \n",
    "    col_sample = [col for col in d_thres.columns if col not in col_blank]\n",
    "    # Sample maximum area vs Blank average area to count for svb\n",
    "    d_sample = d_thres[d_thres[col_sample[4:]].max(axis=1) / d_thres[col_blank].mean(axis=1) > svb_thres][col_sample] \n",
    "    d_sample.reset_index(inplace=True)\n",
    "    d_sample.drop(columns=['index'],inplace=True)\n",
    "    \n",
    "    # Get a list of triplicate, every triplicate is in a sublist\n",
    "    #Sample: [[a1,a2,a3],[b1,b2,b3]]\n",
    "    #Note: the triplicate parsing is now only used '_' which needs update in the future\n",
    "    trip_list = [list(i) for j, i in groupby(d_sample.columns[4:], lambda a: a.split('_')[:-1])] \n",
    "    trip_list = [i for i in trip_list if len(i)>=2] #filter out columns that is not in triplicate -- sample naming issue\n",
    "\n",
    "    for triplicate in tqdm(trip_list):\n",
    "        # DM: maybe use iterrtuples? iterrows has low efficiency and is not reccomended \n",
    "        for row in d_sample[triplicate].itertuples(): # Loop for every sets of triplicates\n",
    "            if row[1:].count(0) > empty_thres:\n",
    "                d_sample.loc[row.Index, triplicate] = 0 # if more than thres, then set all three values to 0\n",
    "            elif np.mean(row[1:]) != 0:\n",
    "                if np.std(row[1:]) / np.mean(row[1:]) > cv_thres:\n",
    "                    d_sample.loc[row.Index, triplicate] = 0 #need verify, not work for now\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    d_sample = d_sample[~(d_sample[d_sample.columns[4:]]==0).all(1)] #clean rows with all 0\n",
    "    \n",
    "    return d_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:04<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "keys=['CEC','Blank','ISTD','Wash','Shutdown']\n",
    "d_sample = data_prep(d_ms,keys,rt_range = [1,30], mz_range = [200,800], area_thres=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. grouping\n",
    "2. noise_rm & filter\n",
    "3. source ID using avg PAs -- consider the score or other labels in the source label?\n",
    "4. calc dilution as below -- score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_label(d_input, sourcelist,area_thres=5000): #noise removal only based on sourcelist cols\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    #source labeling\n",
    "    d_result = d_input.copy()\n",
    "    source_col=[]\n",
    "    for s in sourcelist:\n",
    "        source = [col for col in d_input.columns if s in col]\n",
    "        source_col.append(source)\n",
    "    simp_dict={}\n",
    "    for i, column in enumerate(source_col):\n",
    "        avg = d_result[column].mean(1)\n",
    "        cv = d_result[column].std(1) / d_result[column].mean(1) #optional display CV\n",
    "        simp_dict.update({sourcelist[i]:avg})\n",
    "    d_summary = pd.DataFrame(simp_dict)\n",
    "    d_summary['source']=\"NA\"\n",
    "    for row in d_summary.itertuples():\n",
    "        sourcelabel = list(d_summary.columns[[col_index for col_index, peak_avg in enumerate(row[1:-1]) if peak_avg >= area_thres]])\n",
    "        if len(sourcelabel) != 0:\n",
    "            labelstr = ','.join(sourcelabel)\n",
    "            d_summary.at[row.Index,'source'] = labelstr\n",
    "    d_result['source'] = d_summary['source']\n",
    "    \n",
    "    return d_result, d_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcelist=['Coulter','Crescent','Miller','Swan','SR520-Cal-in-DI_1000mL']\n",
    "d_label, d_simp = source_label(d_sample,sourcelist,area_thres=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User case for coverage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5393298059964726"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(d_label[d_label['20181114_SR520-Creek_Mix6B_1'] >= 1000]['source'].str.contains('SR520')) / sum(d_label['source'].str.contains('SR520'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10336347135237217"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for 2. complicated: consider other source impact\n",
    "# s_simp = d_simp.loc[d_label[d_label['source'].str.contains('SR520')].index]['SR520-Cal-in-DI_1000mL']\n",
    "# mix = d_label[d_label['source'].str.contains('SR520')]['20181114_SR520-Creek_Mix1_1']\n",
    "#1. simple way: only use 520 specific source\n",
    "mix = d_label[d_label['source'] == 'SR520-Cal-in-DI_1000mL']['20181114_SR520-Creek_Mix6A_1']\n",
    "s_simp = d_simp[d_simp['source'] == 'SR520-Cal-in-DI_1000mL']['SR520-Cal-in-DI_1000mL']\n",
    "match_index = [i for i, j in enumerate(mix) if j >= 1000]\n",
    "dilu = mix.iloc[match_index] / s_simp.iloc[match_index]\n",
    "np.average(dilu[dilu<1]) #Calculate the dilution rate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_key = 'Mix'\n",
    "thres = 1000\n",
    "source_key = 'SR520-Cal-in-DI_1000mL'\n",
    "method='multiple'\n",
    "result = []\n",
    "mix_col = [col for col in d_label.columns if mix_key in col]\n",
    "for col in mix_col:\n",
    "    cov_score = sum(d_label[d_label[col] >= thres]['source'].str.contains(source_key)) / sum(d_label['source'].str.contains(source_key))\n",
    "    if method == 'single':\n",
    "        mix = d_label[d_label['source'] == source_key][col]\n",
    "        s_simp = d_simp[d_simp['source'] == source_key][source_key]\n",
    "    elif method == 'multiple':\n",
    "        mix = d_label[d_label['source'].str.contains(source_key)][col]\n",
    "        s_simp = d_simp.loc[d_label[d_label['source'].str.contains(source_key)].index][source_key]\n",
    "    match_index = [i for i, j in enumerate(mix) if j >= thres]\n",
    "    dilu = mix.iloc[match_index] / s_simp.iloc[match_index]\n",
    "    ratio_score = np.average(dilu[dilu<1])\n",
    "    result.append([col, cov_score, ratio_score])\n",
    "    d_st = pd.DataFrame(result, columns = ['sample', 'cov_score', 'ratio_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>cov_score</th>\n",
       "      <th>ratio_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181114_SR520-Creek_Mix1_1</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.696022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181114_SR520-Creek_Mix1_2</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.707796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181114_SR520-Creek_Mix1_3</td>\n",
       "      <td>0.941446</td>\n",
       "      <td>0.715812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181114_SR520-Creek_Mix2_1</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.717283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181114_SR520-Creek_Mix2_2</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.704341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20181114_SR520-Creek_Mix2_3</td>\n",
       "      <td>0.929101</td>\n",
       "      <td>0.709678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20181114_SR520-Creek_Mix3_1</td>\n",
       "      <td>0.868783</td>\n",
       "      <td>0.521747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20181114_SR520-Creek_Mix3_2</td>\n",
       "      <td>0.870194</td>\n",
       "      <td>0.517127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20181114_SR520-Creek_Mix3_3</td>\n",
       "      <td>0.867019</td>\n",
       "      <td>0.520016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20181114_SR520-Creek_Mix4A_1</td>\n",
       "      <td>0.798589</td>\n",
       "      <td>0.369325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20181114_SR520-Creek_Mix4A_2</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.369009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20181114_SR520-Creek_Mix4A_3</td>\n",
       "      <td>0.799295</td>\n",
       "      <td>0.369552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20181114_SR520-Creek_Mix4B_1</td>\n",
       "      <td>0.731922</td>\n",
       "      <td>0.424513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20181114_SR520-Creek_Mix4B_2</td>\n",
       "      <td>0.734039</td>\n",
       "      <td>0.423381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20181114_SR520-Creek_Mix4B_3</td>\n",
       "      <td>0.732981</td>\n",
       "      <td>0.419539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20181114_SR520-Creek_Mix5A_1</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.230272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20181114_SR520-Creek_Mix5A_2</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.231938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20181114_SR520-Creek_Mix5A_3</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.223173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20181114_SR520-Creek_Mix5B_1</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.286734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20181114_SR520-Creek_Mix5B_2</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.286946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20181114_SR520-Creek_Mix5B_3</td>\n",
       "      <td>0.635626</td>\n",
       "      <td>0.289287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20181114_SR520-Creek_Mix6A_1</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>0.216180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20181114_SR520-Creek_Mix6A_2</td>\n",
       "      <td>0.523457</td>\n",
       "      <td>0.215504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20181114_SR520-Creek_Mix6A_3</td>\n",
       "      <td>0.525220</td>\n",
       "      <td>0.219651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20181114_SR520-Creek_Mix6B_1</td>\n",
       "      <td>0.539330</td>\n",
       "      <td>0.211994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20181114_SR520-Creek_Mix6B_2</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20181114_SR520-Creek_Mix6B_3</td>\n",
       "      <td>0.544268</td>\n",
       "      <td>0.209944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sample  cov_score  ratio_score\n",
       "0    20181114_SR520-Creek_Mix1_1   0.941799     0.696022\n",
       "1    20181114_SR520-Creek_Mix1_2   0.941799     0.707796\n",
       "2    20181114_SR520-Creek_Mix1_3   0.941446     0.715812\n",
       "3    20181114_SR520-Creek_Mix2_1   0.928042     0.717283\n",
       "4    20181114_SR520-Creek_Mix2_2   0.928042     0.704341\n",
       "5    20181114_SR520-Creek_Mix2_3   0.929101     0.709678\n",
       "6    20181114_SR520-Creek_Mix3_1   0.868783     0.521747\n",
       "7    20181114_SR520-Creek_Mix3_2   0.870194     0.517127\n",
       "8    20181114_SR520-Creek_Mix3_3   0.867019     0.520016\n",
       "9   20181114_SR520-Creek_Mix4A_1   0.798589     0.369325\n",
       "10  20181114_SR520-Creek_Mix4A_2   0.798942     0.369009\n",
       "11  20181114_SR520-Creek_Mix4A_3   0.799295     0.369552\n",
       "12  20181114_SR520-Creek_Mix4B_1   0.731922     0.424513\n",
       "13  20181114_SR520-Creek_Mix4B_2   0.734039     0.423381\n",
       "14  20181114_SR520-Creek_Mix4B_3   0.732981     0.419539\n",
       "15  20181114_SR520-Creek_Mix5A_1   0.607407     0.230272\n",
       "16  20181114_SR520-Creek_Mix5A_2   0.613757     0.231938\n",
       "17  20181114_SR520-Creek_Mix5A_3   0.606349     0.223173\n",
       "18  20181114_SR520-Creek_Mix5B_1   0.628571     0.286734\n",
       "19  20181114_SR520-Creek_Mix5B_2   0.628571     0.286946\n",
       "20  20181114_SR520-Creek_Mix5B_3   0.635626     0.289287\n",
       "21  20181114_SR520-Creek_Mix6A_1   0.520988     0.216180\n",
       "22  20181114_SR520-Creek_Mix6A_2   0.523457     0.215504\n",
       "23  20181114_SR520-Creek_Mix6A_3   0.525220     0.219651\n",
       "24  20181114_SR520-Creek_Mix6B_1   0.539330     0.211994\n",
       "25  20181114_SR520-Creek_Mix6B_2   0.539683     0.213612\n",
       "26  20181114_SR520-Creek_Mix6B_3   0.544268     0.209944"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_st #wrap it into function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first --> assign label to different features\n",
    "\n",
    "second --> ID using the features\n",
    "\n",
    "third --> assessment, for instance, final ID confidence = 50% feature quantity score + 50% feature intensity score\n",
    "\n",
    "sample A have 50% of source A feature, avg intensity ratio(5~95%) is 90%, then score = $0.5*0.5(feature #)+0.5*0.9$ (major feature intensity)\n",
    "\n",
    "for approportioning calculation --> matrix effect needs to be overcome --> more samples and data needed and will be a long term dev & validation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample output for score assignment using label information:\n",
    "\n",
    "|sample name|coverage score| intensity score | final score|\n",
    "|---|---|---|---|\n",
    "|sample1|0.5|0.3|0.4|\n",
    "|sample2|a|b|c|\n",
    "\n",
    "|sample name|coverage score1(5-25%)|coverage score2(25-50%)|coverage score3(50-75%)|\n",
    "|---|---|---|---|\n",
    "|sample1|0.5|0.3|0.4|\n",
    "|sample2|a|b|c|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
