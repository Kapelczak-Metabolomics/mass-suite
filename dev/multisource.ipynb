{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster,mixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "from pandas.core.common import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "blank removal --> noise removal --> find unique/shared clusters --> use information for id --> use information for tracking\n",
    "```\n",
    "sudo code:\n",
    "picking up sources\n",
    "output labeled table\n",
    "use the information for the source id\n",
    "\n",
    "two way:\n",
    "1. venn diagram --> source id\n",
    "2. more data: single source approach to identify clusters for different sources and use the modeling approach for source tracking\n",
    "```\n",
    "\n",
    "important : tweak the parameters during venn diagram approach\n",
    "\n",
    "Two ways: use source data + venn diagram, give unique cluster higher score and shared cluster lower score, given a new sample, can predict the source id, or assign with possibility scores, for instance >70% of cluster features present then the shource exists. Hard to do source tracking since matrix effect and dilution effect is not considered\n",
    "\n",
    "better way with more data: every source with dilution series, and use the single source approach to find clusters, and modeling for the source approportioning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = pd.read_csv('../example_data/clustering/sample1114.csv')\n",
    "d_ms = d_ms.rename(columns={'Average Rt(min)': 'Average RT (min)', 'Average Mz': 'Average m/z', 'S/N average': 'Average sn'})\n",
    "d_ms.insert(3, \"Average score\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(d_input, blank_keyword, simp_summary = False,svb_thres=10, empty_thres=0,rt_range=[0, 30], mz_range=[0, 1200], sn_thres=3, score_thres=0, area_thres=5000):\n",
    "    '''\n",
    "    The function is used to clean the dataframe according to user setting\n",
    "    blank_keyword: part of string from column that indicates the column is a blank sample\n",
    "    svb_thres: sample vs blank thres\n",
    "    empty_thres: empty cell thres in a row\n",
    "    cv_thres: as all sample is in triplicate, calculate the CV for every triplicate sample set #Needs to be updated in case there is no triplicate samples\n",
    "    rt_range: rt filter\n",
    "    mz_range: mz filter\n",
    "    sn_thres: signal/noise column thres\n",
    "    score_thres: score column thres\n",
    "    area_thres: count for max peak area from each row\n",
    "    '''\n",
    "    d_thres = d_input[d_input[d_input.columns[4:]].max(1) >= area_thres]\n",
    "    \n",
    "    d_thres = d_thres[(d_thres['Average RT (min)'] > rt_range[0]) & (d_thres['Average RT (min)'] < rt_range[1])]\n",
    "    d_thres = d_thres[(d_thres['Average m/z'] > mz_range[0]) & (d_thres['Average m/z'] < mz_range[1])]\n",
    "    d_thres = d_thres[d_thres['Average sn'] >= sn_thres]\n",
    "    d_thres = d_thres[d_thres['Average score'] >= score_thres]\n",
    "    d_thres.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    col_blank = []\n",
    "    for key in blank_keyword:\n",
    "        # Get column name if it contains blank indicating strings\n",
    "        col_blank.extend([col for col in d_thres.columns if key in col])\n",
    "        \n",
    "    col_sample = [col for col in d_thres.columns if col not in col_blank]\n",
    "    # Sample maximum area vs Blank average area to count for svb\n",
    "    d_sample = d_thres[d_thres[col_sample[4:]].max(axis=1) / d_thres[col_blank].mean(axis=1) > svb_thres][col_sample] \n",
    "    d_sample.reset_index(inplace=True)\n",
    "    d_sample.drop(columns=['index'],inplace=True)\n",
    "    \n",
    "    # Get a list of triplicate, every triplicate is in a sublist\n",
    "    #Sample: [[a1,a2,a3],[b1,b2,b3]]\n",
    "    #Note: the triplicate parsing is now only used '_' which needs update in the future\n",
    "    #d_transpose['dilu_vol'] = d_transpose['dilu_vol'].apply(lambda x : x.replace('-','_')) in case people use '-' for parsing\n",
    "    trip_list = [list(i) for j, i in groupby(d_sample.columns[4:], lambda a: a.split('_')[:-1])] \n",
    "    trip_list = [i for i in trip_list if len(i)>=2] #filter out columns that is not in triplicate -- sample naming issue\n",
    "\n",
    "    for triplicate in tqdm(trip_list):\n",
    "        for row in d_sample[triplicate].itertuples(): # Loop for every sets of triplicates\n",
    "            if row[1:].count(0) > empty_thres:\n",
    "                d_sample.loc[row.Index, triplicate] = 0 # if more than thres, then set all three values to 0\n",
    "#             elif np.mean(row[1:]) != 0:\n",
    "#                 if np.std(row[1:]) / np.mean(row[1:]) > cv_thres:\n",
    "#                     d_sample.loc[row.Index, triplicate] = 0 #need verify, not work for now\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    d_sample = d_sample[~(d_sample[d_sample.columns[4:]]==0).all(1)] #clean rows with all 0\n",
    "    if simp_summary == True:\n",
    "        simp_dict={}\n",
    "        for i, column in enumerate(trip_list):\n",
    "            avg = d_sample[column].mean(1)\n",
    "            cv = d_sample[column].std(1) / d_sample[column].mean(1) #optional display CV\n",
    "            simp_dict.update({column[0][:-2]:avg, ' CV #' + str(i):cv})\n",
    "        d_result = pd.DataFrame(simp_dict)\n",
    "        d_result = pd.concat([d_sample[d_sample.columns[:4]], d_result], axis=1)\n",
    "    elif simp_summary == False:\n",
    "        d_result = d_sample.copy()\n",
    "    \n",
    "    return d_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average RT (min)</th>\n",
       "      <th>Average m/z</th>\n",
       "      <th>Average sn</th>\n",
       "      <th>Average score</th>\n",
       "      <th>20181114_CoulterCreek_1</th>\n",
       "      <th>20181114_CoulterCreek_2</th>\n",
       "      <th>20181114_CoulterCreek_3</th>\n",
       "      <th>20181114_Crescent-Creek-Jan_1</th>\n",
       "      <th>20181114_Crescent-Creek-Jan_2</th>\n",
       "      <th>20181114_Crescent-Creek-Jan_3</th>\n",
       "      <th>...</th>\n",
       "      <th>20181114_SR520-Creek_Mix6A_3</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_1</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_2</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_3</th>\n",
       "      <th>20181114_SwanCreek-Dec_1</th>\n",
       "      <th>20181114_SwanCreek-Dec_2</th>\n",
       "      <th>20181114_SwanCreek-Dec_3</th>\n",
       "      <th>20181114_SwanCreek-May_1</th>\n",
       "      <th>20181114_SwanCreek-May_2</th>\n",
       "      <th>20181114_SwanCreek-May_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.696</td>\n",
       "      <td>200.07405</td>\n",
       "      <td>35.03</td>\n",
       "      <td>1</td>\n",
       "      <td>3339</td>\n",
       "      <td>2477</td>\n",
       "      <td>3796</td>\n",
       "      <td>4698</td>\n",
       "      <td>3918</td>\n",
       "      <td>2252</td>\n",
       "      <td>...</td>\n",
       "      <td>3769</td>\n",
       "      <td>5471</td>\n",
       "      <td>5255</td>\n",
       "      <td>5571</td>\n",
       "      <td>4397</td>\n",
       "      <td>5408</td>\n",
       "      <td>5311</td>\n",
       "      <td>3060</td>\n",
       "      <td>2645</td>\n",
       "      <td>2647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.326</td>\n",
       "      <td>200.12823</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1791</td>\n",
       "      <td>2769</td>\n",
       "      <td>2955</td>\n",
       "      <td>2544</td>\n",
       "      <td>1265</td>\n",
       "      <td>2225</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2429</td>\n",
       "      <td>1507</td>\n",
       "      <td>1572</td>\n",
       "      <td>539</td>\n",
       "      <td>2316</td>\n",
       "      <td>2175</td>\n",
       "      <td>3045</td>\n",
       "      <td>1496</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.220</td>\n",
       "      <td>200.12869</td>\n",
       "      <td>29.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2586</td>\n",
       "      <td>1877</td>\n",
       "      <td>2674</td>\n",
       "      <td>4057</td>\n",
       "      <td>3302</td>\n",
       "      <td>4223</td>\n",
       "      <td>...</td>\n",
       "      <td>2389</td>\n",
       "      <td>2229</td>\n",
       "      <td>2068</td>\n",
       "      <td>4053</td>\n",
       "      <td>1055</td>\n",
       "      <td>2186</td>\n",
       "      <td>1263</td>\n",
       "      <td>1387</td>\n",
       "      <td>2033</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.920</td>\n",
       "      <td>200.16484</td>\n",
       "      <td>192.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1403</td>\n",
       "      <td>166</td>\n",
       "      <td>137</td>\n",
       "      <td>679</td>\n",
       "      <td>388</td>\n",
       "      <td>677</td>\n",
       "      <td>...</td>\n",
       "      <td>6572</td>\n",
       "      <td>7230</td>\n",
       "      <td>10364</td>\n",
       "      <td>8871</td>\n",
       "      <td>772</td>\n",
       "      <td>1658</td>\n",
       "      <td>1421</td>\n",
       "      <td>660</td>\n",
       "      <td>474</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.295</td>\n",
       "      <td>200.20181</td>\n",
       "      <td>23.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>571</td>\n",
       "      <td>232</td>\n",
       "      <td>868</td>\n",
       "      <td>211</td>\n",
       "      <td>141</td>\n",
       "      <td>193</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>13.722</td>\n",
       "      <td>796.54181</td>\n",
       "      <td>72.80</td>\n",
       "      <td>1</td>\n",
       "      <td>3287</td>\n",
       "      <td>1666</td>\n",
       "      <td>1874</td>\n",
       "      <td>522</td>\n",
       "      <td>877</td>\n",
       "      <td>1666</td>\n",
       "      <td>...</td>\n",
       "      <td>2243</td>\n",
       "      <td>3766</td>\n",
       "      <td>4044</td>\n",
       "      <td>2141</td>\n",
       "      <td>1317</td>\n",
       "      <td>1430</td>\n",
       "      <td>1557</td>\n",
       "      <td>707</td>\n",
       "      <td>1621</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>19.664</td>\n",
       "      <td>796.68024</td>\n",
       "      <td>64.91</td>\n",
       "      <td>1</td>\n",
       "      <td>6486</td>\n",
       "      <td>11286</td>\n",
       "      <td>11809</td>\n",
       "      <td>1949</td>\n",
       "      <td>698</td>\n",
       "      <td>1904</td>\n",
       "      <td>...</td>\n",
       "      <td>2254</td>\n",
       "      <td>3491</td>\n",
       "      <td>1027</td>\n",
       "      <td>1102</td>\n",
       "      <td>1127</td>\n",
       "      <td>527</td>\n",
       "      <td>562</td>\n",
       "      <td>678</td>\n",
       "      <td>1562</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>18.050</td>\n",
       "      <td>797.51886</td>\n",
       "      <td>17.14</td>\n",
       "      <td>1</td>\n",
       "      <td>2482</td>\n",
       "      <td>1489</td>\n",
       "      <td>756</td>\n",
       "      <td>498</td>\n",
       "      <td>678</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>780</td>\n",
       "      <td>278</td>\n",
       "      <td>206</td>\n",
       "      <td>787</td>\n",
       "      <td>832</td>\n",
       "      <td>650</td>\n",
       "      <td>508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>5.058</td>\n",
       "      <td>798.47003</td>\n",
       "      <td>24.24</td>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>673</td>\n",
       "      <td>401</td>\n",
       "      <td>245</td>\n",
       "      <td>169</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>809</td>\n",
       "      <td>560</td>\n",
       "      <td>859</td>\n",
       "      <td>1091</td>\n",
       "      <td>438</td>\n",
       "      <td>265</td>\n",
       "      <td>89</td>\n",
       "      <td>194</td>\n",
       "      <td>357</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>14.247</td>\n",
       "      <td>799.62860</td>\n",
       "      <td>10.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5299 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Average RT (min)  Average m/z  Average sn  Average score  \\\n",
       "0                5.696    200.07405       35.03              1   \n",
       "1                4.326    200.12823       16.90              1   \n",
       "2                4.220    200.12869       29.97              1   \n",
       "3                5.920    200.16484      192.03              1   \n",
       "4                5.295    200.20181       23.37              1   \n",
       "...                ...          ...         ...            ...   \n",
       "5295            13.722    796.54181       72.80              1   \n",
       "5296            19.664    796.68024       64.91              1   \n",
       "5297            18.050    797.51886       17.14              1   \n",
       "5298             5.058    798.47003       24.24              1   \n",
       "5299            14.247    799.62860       10.01              1   \n",
       "\n",
       "      20181114_CoulterCreek_1  20181114_CoulterCreek_2  \\\n",
       "0                        3339                     2477   \n",
       "1                        1791                     2769   \n",
       "2                        2586                     1877   \n",
       "3                        1403                      166   \n",
       "4                           0                        0   \n",
       "...                       ...                      ...   \n",
       "5295                     3287                     1666   \n",
       "5296                     6486                    11286   \n",
       "5297                     2482                     1489   \n",
       "5298                      457                      673   \n",
       "5299                        0                        0   \n",
       "\n",
       "      20181114_CoulterCreek_3  20181114_Crescent-Creek-Jan_1  \\\n",
       "0                        3796                           4698   \n",
       "1                        2955                           2544   \n",
       "2                        2674                           4057   \n",
       "3                         137                            679   \n",
       "4                           0                              0   \n",
       "...                       ...                            ...   \n",
       "5295                     1874                            522   \n",
       "5296                    11809                           1949   \n",
       "5297                      756                            498   \n",
       "5298                      401                            245   \n",
       "5299                        0                              0   \n",
       "\n",
       "      20181114_Crescent-Creek-Jan_2  20181114_Crescent-Creek-Jan_3  ...  \\\n",
       "0                              3918                           2252  ...   \n",
       "1                              1265                           2225  ...   \n",
       "2                              3302                           4223  ...   \n",
       "3                               388                            677  ...   \n",
       "4                                 0                              0  ...   \n",
       "...                             ...                            ...  ...   \n",
       "5295                            877                           1666  ...   \n",
       "5296                            698                           1904  ...   \n",
       "5297                            678                            466  ...   \n",
       "5298                            169                            163  ...   \n",
       "5299                              0                              0  ...   \n",
       "\n",
       "      20181114_SR520-Creek_Mix6A_3  20181114_SR520-Creek_Mix6B_1  \\\n",
       "0                             3769                          5471   \n",
       "1                             2000                          2429   \n",
       "2                             2389                          2229   \n",
       "3                             6572                          7230   \n",
       "4                              188                           571   \n",
       "...                            ...                           ...   \n",
       "5295                          2243                          3766   \n",
       "5296                          2254                          3491   \n",
       "5297                           780                           278   \n",
       "5298                           809                           560   \n",
       "5299                             0                             0   \n",
       "\n",
       "      20181114_SR520-Creek_Mix6B_2  20181114_SR520-Creek_Mix6B_3  \\\n",
       "0                             5255                          5571   \n",
       "1                             1507                          1572   \n",
       "2                             2068                          4053   \n",
       "3                            10364                          8871   \n",
       "4                              232                           868   \n",
       "...                            ...                           ...   \n",
       "5295                          4044                          2141   \n",
       "5296                          1027                          1102   \n",
       "5297                           206                           787   \n",
       "5298                           859                          1091   \n",
       "5299                             0                             0   \n",
       "\n",
       "      20181114_SwanCreek-Dec_1  20181114_SwanCreek-Dec_2  \\\n",
       "0                         4397                      5408   \n",
       "1                          539                      2316   \n",
       "2                         1055                      2186   \n",
       "3                          772                      1658   \n",
       "4                          211                       141   \n",
       "...                        ...                       ...   \n",
       "5295                      1317                      1430   \n",
       "5296                      1127                       527   \n",
       "5297                       832                       650   \n",
       "5298                       438                       265   \n",
       "5299                         0                         0   \n",
       "\n",
       "      20181114_SwanCreek-Dec_3  20181114_SwanCreek-May_1  \\\n",
       "0                         5311                      3060   \n",
       "1                         2175                      3045   \n",
       "2                         1263                      1387   \n",
       "3                         1421                       660   \n",
       "4                          193                       372   \n",
       "...                        ...                       ...   \n",
       "5295                      1557                       707   \n",
       "5296                       562                       678   \n",
       "5297                       508                         0   \n",
       "5298                        89                       194   \n",
       "5299                         0                         0   \n",
       "\n",
       "      20181114_SwanCreek-May_2  20181114_SwanCreek-May_3  \n",
       "0                         2645                      2647  \n",
       "1                         1496                       802  \n",
       "2                         2033                      2486  \n",
       "3                          474                       368  \n",
       "4                           96                       333  \n",
       "...                        ...                       ...  \n",
       "5295                      1621                       770  \n",
       "5296                      1562                      1144  \n",
       "5297                         0                         0  \n",
       "5298                       357                       178  \n",
       "5299                         0                         0  \n",
       "\n",
       "[5299 rows x 112 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:40<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "keys=['CEC','Blank','ISTD','Wash','Shutdown']\n",
    "d_sample = data_prep(d_ms,keys,rt_range = [1,30], mz_range = [200,800], area_thres=500, simp_summary = False) # The function now only deal with triplicate samples\n",
    "#Needs to refine towards case that don't have 3 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. grouping\n",
    "2. noise_rm & filter\n",
    "3. source ID using avg PAs -- consider the score or other labels in the source label?\n",
    "4. calc dilution as below -- score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_label(d_input, sourcelist,area_thres=5000, concat = True): #noise removal only based on sourcelist cols\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    #source labeling\n",
    "    d_result = d_input.copy()\n",
    "    source_col=[]\n",
    "    for s in sourcelist:\n",
    "        source = [col for col in d_input.columns if s in col]\n",
    "        source_col.append(source)\n",
    "    simp_dict={}\n",
    "    for i, column in enumerate(source_col):\n",
    "        avg = d_result[column].mean(1)\n",
    "        cv = d_result[column].std(1) / d_result[column].mean(1) #optional display CV\n",
    "        cv_nan=np.isnan(cv)\n",
    "        cv[cv_nan]=0.0 #replace nan with 0\n",
    "        simp_dict.update({sourcelist[i]:avg, str(sourcelist[i])+' Cv':cv})\n",
    "    d_summary = pd.DataFrame(simp_dict)\n",
    "    d_summary['source']=\"NA\"\n",
    "    for row in d_summary.itertuples():\n",
    "        sourcelabel = list(d_summary.columns[[col_index for col_index, peak_avg in enumerate(row[1:-1]) if peak_avg >= area_thres]])\n",
    "        if len(sourcelabel) != 0:\n",
    "            labelstr = ','.join(sourcelabel)\n",
    "            d_summary.at[row.Index,'source'] = labelstr\n",
    "    if concat == True:\n",
    "        d_concat = pd.concat([d_result, d_summary], axis=1)\n",
    "    elif concat == False:\n",
    "        d_concat=d_result.copy()\n",
    "        d_concat['source'] = d_summary['source']\n",
    "    \n",
    "    return d_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_label['source'].dtype == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcelist=['Coulter','Crescent','Miller','Swan','SR520-Cal-in-DI_1000mL'] #Needs adjustment\n",
    "d_label = source_label(d_sample,sourcelist,area_thres= 50000,concat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User case for coverage score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorithm flow:\n",
    "\n",
    "1. simplify the chart to mean values, exclude CV variant ones\n",
    "2. using venn diagram idea, label the source according to mean peak area threshold\n",
    "3. get coverage score using the label information and get the intensity score similarly\n",
    "```\n",
    "but consider the matrix effect and unknowns to the sample, validation is required and more dedication & combination is needed\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_report(d_input, source_key, mix_key, method='multiple', pa_thres=10000, CV_thres=2): #source key needs to be the same as source_label above\n",
    "    #**only take the concat dataframe from labeling function\n",
    "    #prefilter & dataframe arrangement\n",
    "    d_mix = d_input[(d_input[[col for col in d_input.columns if 'Cv' in col]] <= CV_thres).all(1)]# all cv should below thres in order to be checked\n",
    "    d_simp = d_mix[source_key]\n",
    "    print('Threshold set to', thres)\n",
    "    mix_col = []\n",
    "    for key in mix_key:\n",
    "        mix_col.extend([col for col in d_mix.columns if 'Mix' in col])\n",
    "    if len(mix_col) == 0:\n",
    "        print(\"didn't find mixture by keyword!\")\n",
    "    source_col = []\n",
    "\n",
    "    d_st = pd.DataFrame(mix_col)\n",
    "\n",
    "    c_name = ['sample']\n",
    "    for source in source_key:\n",
    "        result = []\n",
    "        for col in mix_col:\n",
    "            n_feature = sum(d_mix[d_mix[col] >= thres]['source'].str.contains(source))\n",
    "            cov_score = n_feature / sum(d_mix['source'].str.contains(source))\n",
    "            if method == 'single':\n",
    "                mix = d_mix[d_mix['source'] == source][col]\n",
    "                s_simp = d_simp[d_simp['source'] == source][source]\n",
    "            elif method == 'multiple':\n",
    "                mix = d_mix[d_mix['source'].str.contains(source)][col]\n",
    "                s_simp = d_simp.loc[d_mix[d_mix['source'].str.contains(source)].index][source]\n",
    "            match_index = [i for i, j in enumerate(mix) if j >= thres]\n",
    "            dilu = mix.iloc[match_index] / s_simp.iloc[match_index]\n",
    "            ratio_score = np.average(dilu[dilu<1])\n",
    "            result.append([n_feature, cov_score, ratio_score])\n",
    "        d_st = pd.concat([d_st, pd.DataFrame(result)], axis = 1)\n",
    "        c_name.extend(['n_'+str(source), 'cover_s', 'ratio_s'])\n",
    "    d_st.columns = c_name\n",
    "    \n",
    "    return d_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to 5000\n"
     ]
    }
   ],
   "source": [
    "d_t = source_report(d_label, ['Coulter','Crescent','Miller','Swan','SR520-Cal-in-DI_1000mL'], ['Mix'], method='multiple', pa_thres=10000, CV_thres=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further comparison:\n",
    "\n",
    "ref Kathy's paper, compare the d_st with the cluster result/modeling report, further sort our features that is overlapping or meeting the criteria (table1 from the paper) to generate a detailed source tracking report use both source information and dilution information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization based on single sample\n",
    "\n",
    "chart based on all \n",
    "\n",
    "|sample name|feature from source1|coverage score source1|etc2|etc2|\n",
    "|---|---|---|---|---|\n",
    "|sample1|1800|0.3|2000|0.5|\n",
    "|sample2|a|b|c|d|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first --> assign label to different features\n",
    "\n",
    "second --> ID using the features\n",
    "\n",
    "third --> assessment, for instance, final ID confidence = 50% feature quantity score + 50% feature intensity score\n",
    "\n",
    "sample A have 50% of source A feature, avg intensity ratio(5~95%) is 90%, then score = $0.5*0.5(feature #)+0.5*0.9$ (major feature intensity)\n",
    "\n",
    "for approportioning calculation --> matrix effect needs to be overcome --> more samples and data needed and will be a long term dev & validation process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
