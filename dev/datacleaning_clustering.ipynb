{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster,mixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = pd.read_csv('../example_data/clustering/sample1114.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = d_ms.rename(columns={'Average Rt(min)': 'Average RT (min)', 'Average Mz': 'Average m/z', 'S/N average': 'Average sn'})\n",
    "d_ms.insert(3, \"Average score\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=['CEC','Blank','ISTD','Wash','Shutdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(d_input, blank_keyword, svb_thres=10, empty_thres=0, cv_thres=5,rt_range=[0, 30], mz_range=[0, 1200], sn_thres=3, score_thres=0, area_thres=5000):\n",
    "    '''\n",
    "    The function is used to clean the dataframe according to user setting\n",
    "    blank_keyword: part of string from column that indicates the column is a blank sample\n",
    "    svb_thres: sample vs blank thres\n",
    "    empty_thres: empty cell thres in a row\n",
    "    cv_thres: as all sample is in triplicate, calculate the CV for every triplicate sample set #Needs to be updated in case there is no triplicate samples\n",
    "    rt_range: rt filter\n",
    "    mz_range: mz filter\n",
    "    sn_thres: signal/noise column thres\n",
    "    score_thres: score column thres\n",
    "    area_thres: count for max peak area from each row\n",
    "    '''\n",
    "    d_thres = d_input[d_input[d_input.columns[4:]].max(1) >= area_thres]\n",
    "    \n",
    "    d_thres = d_thres[(d_thres['Average RT (min)'] > rt_range[0]) & (d_thres['Average RT (min)'] < rt_range[1])]\n",
    "    d_thres = d_thres[(d_thres['Average m/z'] > mz_range[0]) & (d_thres['Average m/z'] < mz_range[1])]\n",
    "    d_thres = d_thres[d_thres['Average sn'] >= sn_thres]\n",
    "    d_thres = d_thres[d_thres['Average score'] >= score_thres]\n",
    "    d_thres.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    col_blank = []\n",
    "    for key in blank_keyword:\n",
    "        # Get column name if it contains blank indicating strings\n",
    "        col_blank.extend([col for col in d_thres.columns if key in col])\n",
    "        \n",
    "    col_sample = [col for col in d_thres.columns if col not in col_blank]\n",
    "    # Sample maximum area vs Blank average area to count for svb\n",
    "    d_sample = d_thres[d_thres[col_sample[4:]].max(axis=1) / d_thres[col_blank].mean(axis=1) > svb_thres][col_sample] \n",
    "    d_sample.reset_index(inplace=True)\n",
    "    d_sample.drop(columns=['index'],inplace=True)\n",
    "    \n",
    "    # Get a list of triplicate, every triplicate is in a sublist\n",
    "    #Sample: [[a1,a2,a3],[b1,b2,b3]]\n",
    "    #Note: the triplicate parsing is now only used '_' which needs update in the future\n",
    "    trip_list = [list(i) for j, i in groupby(d_sample.columns[4:], lambda a: a.split('_')[:-1])] \n",
    "    trip_list = [i for i in trip_list if len(i)>=2] #filter out columns that is not in triplicate -- sample naming issue\n",
    "\n",
    "    for triplicate in tqdm(trip_list):\n",
    "        # DM: maybe use iterrtuples? iterrows has low efficiency and is not reccomended \n",
    "        for row in d_sample[triplicate].itertuples(): # Loop for every sets of triplicates\n",
    "            if row[1:].count(0) > empty_thres:\n",
    "                d_sample.loc[row.Index, triplicate] = 0 # if more than thres, then set all three values to 0\n",
    "            elif np.mean(row[1:]) != 0:\n",
    "                if np.std(row[1:]) / np.mean(row[1:]) > cv_thres:\n",
    "                    d_sample.loc[row.Index, triplicate] = 0 #If delete or reduce all number to avg?\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    d_sample = d_sample[~(d_sample[d_sample.columns[4:]]==0).all(1)] #clean rows with all 0\n",
    "    \n",
    "    return d_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:12<00:00,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "d_sample = data_prep(d_ms,keys,rt_range = [1,30], mz_range = [200,800], area_thres=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_cluster(d_input, select_keyword, normalization='linear', visual=False, d_reduce=True, d_reduce_method='tsne', perplexity=20, cluster_method='dbscan',eps=0.8,min_samples=10):\n",
    "    '''\n",
    "    Function for direct clustering:\n",
    "    normalization method: linear, zscore, log\n",
    "    d_reduce: if perform the dimension reduction algorithm, method: only tsne is avilable now\n",
    "    perplexity: parameter for tsne\n",
    "    cluster_method: dbscan, later will update optic and spectrum\n",
    "    eps: parameter for dbscan, threshold of radius that used to count neighbours\n",
    "    min_samples: general parameter for clustering, min neighbourhoods to be counted as a cluster\n",
    "    '''\n",
    "    col_select = []\n",
    "    for key in select_keyword:\n",
    "        col_select.extend([col for col in d_input.columns if key in col])\n",
    "    d_clu = d_input[col_select]\n",
    "    \n",
    "    c_data = d_clu.values\n",
    "    c_norm = []\n",
    "    #Performs normalization\n",
    "    np.seterr(divide='ignore', invalid='ignore') #silent the warning -- but divide by 0 still exist\n",
    "    for row in c_data:\n",
    "        if normalization == 'linear':\n",
    "            c_norm.append(row/max(row))\n",
    "        elif normalization == 'zscore':\n",
    "            c_norm.append((row-np.mean(row))/np.std(row))\n",
    "        elif normalization == 'log':\n",
    "            row[row==0]=1\n",
    "            c_norm.append(np.log10(row)/np.log10(max(row)))\n",
    "        else:\n",
    "            pass\n",
    "    #Clean up dataframe\n",
    "    c_norm = np.asarray(c_norm)\n",
    "    d_norm = pd.DataFrame(c_norm)\n",
    "    d_norm['index']=d_sample.index\n",
    "    d_norm.set_index('index',inplace=True)\n",
    "    d_norm.dropna(how='all',inplace=True)\n",
    "    \n",
    "    if d_reduce == True:\n",
    "        if d_reduce_method == 'tsne':\n",
    "            model = TSNE(learning_rate=100,perplexity=50,n_iter=1000) #Tune perplexity and n_iter\n",
    "            transformed = model.fit_transform(d_norm)\n",
    "            d_feature = transformed.copy()\n",
    "        else:\n",
    "            pass\n",
    "    elif d_reduce == False:\n",
    "        d_feature = d_norm.copy()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if cluster_method == 'dbscan':\n",
    "        dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples).fit(d_feature)\n",
    "        labels = dbscan.labels_\n",
    "        unique_labels = set(dbscan.labels_)\n",
    "        \n",
    "        if visual == True:\n",
    "            for i,k in enumerate(unique_labels):\n",
    "                indexlist = list(np.argwhere(labels==k).reshape(1,-1)[0])\n",
    "                sns.clustermap(d_norm.iloc[indexlist].values,cmap='Reds',col_cluster=True,yticklabels=False,xticklabels=False,figsize=(5,5))\n",
    "                plt.title(str(dbscan)+'label='+ str(k))\n",
    "                plt.show()\n",
    "        else:\n",
    "            pass\n",
    "        d_init = d_sample.copy()\n",
    "        d_label = d_init.loc[d_norm.index] #Use the index to match back to the original datasheet\n",
    "        d_label.insert(4,\"label\", dbscan.labels_.tolist())\n",
    "    elif cluster_method == 'optics':\n",
    "        optics = cluster.OPTICS(min_samples=min_samples).fit(d_feature)\n",
    "        labels = optics.labels_\n",
    "        unique_labels = set(optics.labels_)\n",
    "        if visual == True:\n",
    "            for i,k in enumerate(unique_labels):\n",
    "                indexlist = list(np.argwhere(labels==k).reshape(1,-1)[0])\n",
    "                sns.clustermap(d_norm.iloc[indexlist].values,cmap='Reds',col_cluster=True,yticklabels=False,xticklabels=False,figsize=(5,5))\n",
    "                plt.title(str(optics)+'label='+ str(k))\n",
    "                plt.show()\n",
    "        else:\n",
    "            pass\n",
    "        d_init = d_sample.copy()\n",
    "        d_label = d_init.loc[d_norm.index] #Use the index to match back to the original datasheet\n",
    "        d_label.insert(4,\"label\", optics.labels_.tolist())\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Post filter -- filter out features that present in other sources but not SR520 -- keep it open for now\n",
    "    #If activate add one more variable:source_keyword\n",
    "#     col_source = []\n",
    "#     for key in source_keyword:\n",
    "#         col_app = [col for col in d_thres.columns if key in col]\n",
    "#         col_source += col_app\n",
    "#     col_rest = [col for col in d_label.columns if col not in source][5:]\n",
    "#     d_label[col_app].max(1) / d_label[col_rest].max(1)\n",
    "    \n",
    "    return d_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_label = ms_cluster(d_sample, ['SR520-Cal'], 'linear', d_reduce=False, visual=False, cluster_method='dbscan', eps=0.6, min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options: all_data/clusters seperately\n",
    "# models: multiple linear/ random forest/ etc..\n",
    "# def modeling:\n",
    "#     select option\n",
    "#     select model\n",
    "#     if option all_data:\n",
    "#         model.fit(data) --> training 1114data, test 0815data\n",
    "#     elif option cluster:\n",
    "#         for group in cluster:\n",
    "#             model.fit(group)\n",
    "#         all_model -- > final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post filtering of dilution cluster\n",
    "# source tracking:\n",
    "#     1. samples from different sites\n",
    "#     2. vann diagram--> 'source subtraction' --> unique features for different source\n",
    "#     3. use cluster/noise distinguish method --> remove noises, get clusters\n",
    "#     4. source proportioning prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Clustering Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_calc(d_input, select_keyword, min_size=5, normalization='linear', method='pearsonr',visual=True):\n",
    "    \"\"\"This function calculates clustering based on the pearson correlation.\n",
    "    It takes in a dataframe and a user defined value for what qualifies as a cluster.\n",
    "    User can choose whether or not to have a visual plot of the scatter with True/False.\"\"\"\n",
    "    col_select = []\n",
    "    for key in select_keyword:\n",
    "        col_app = [col for col in d_input.columns if key in col]\n",
    "        col_select += col_app\n",
    "    d_clu = d_input[col_select]\n",
    "    \n",
    "    c_data = d_clu.values\n",
    "    c_norm = []\n",
    "    for row in c_data:\n",
    "        if normalization == 'linear':\n",
    "            c_norm.append(row/max(row))\n",
    "        elif normalization == 'zscore':\n",
    "            c_norm.append((row-np.mean(row))/np.std(row))\n",
    "        elif normalization == 'log':\n",
    "            row[row==0]=1\n",
    "            c_norm.append(np.log10(row)/np.log10(max(row)))\n",
    "    c_norm = np.asarray(c_norm)\n",
    "    d_norm = pd.DataFrame(c_norm)\n",
    "    d_norm['index']=d_sample.index\n",
    "    d_norm.set_index('index',inplace=True)\n",
    "    d_norm.dropna(how='all',inplace=True)\n",
    "    \n",
    "    #Post treatment to fit the d_norm into original codes\n",
    "    d_norm.insert(0,\"RT\", d_label['Average RT (min)'].tolist())\n",
    "    d_norm.insert(1,\"MZ\", d_label['Average m/z'].tolist())\n",
    "    d_norm = d_norm.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #Original codes\n",
    "    cluster = [] # individual cluster holder\n",
    "    cluster_sum = [] # total clusters\n",
    "    drop_list = [] # rows that are dropped from the df\n",
    "    noise = [] # list for containing noise features\n",
    "    while len(d_norm) > 0:\n",
    "        for row in range(len(d_norm)):\n",
    "            feature_1 = d_norm.iloc[0]\n",
    "            feature_2 = d_norm.iloc[row]\n",
    "            if method == 'pearsonr':\n",
    "                corr, p_val = scipy.stats.pearsonr(d_norm.iloc[0, 2:], d_norm.iloc[row, 2:]) \n",
    "            elif method == 'mannwhitneyu':\n",
    "                corr, p_val = scipy.stats.mannwhitneyu(d_norm.iloc[0, 2:], d_norm.iloc[row, 2:]) \n",
    "            elif method == 'kruskal':\n",
    "                corr, p_val = scipy.stats.kruskal(d_norm.iloc[0, 2:], d_norm.iloc[row, 2:]) \n",
    "            if p_val < 0.05:\n",
    "                drop_list.append(row)\n",
    "                cluster += [feature_2]\n",
    "            else:\n",
    "                pass\n",
    "        if len(cluster) <= min_size:\n",
    "            noise += [cluster]\n",
    "            cluster = []\n",
    "        else:\n",
    "            cluster_sum += [cluster]\n",
    "            cluster = []\n",
    "        d_norm = d_norm.drop(drop_list)\n",
    "        d_norm = d_norm.reset_index(drop=True)\n",
    "        drop_list = []\n",
    "    append_list = []\n",
    "    for i in range(len(cluster_sum)):\n",
    "        for j in range(len(cluster_sum[i])):\n",
    "            cluster_sum[i][j].loc['Score']= i\n",
    "            listing = np.array(cluster_sum[i][j])\n",
    "            append_list.append(listing)\n",
    "    cluster_df = pd.DataFrame(append_list) #Add columns use d_clu\n",
    "    append_list2 = []\n",
    "    for k in range(len(noise)):\n",
    "        for l in range(len(noise[k])):\n",
    "            noise[k][l].loc['Score']= -1\n",
    "            listing2 = np.array(noise[k][l])\n",
    "            append_list2.append(listing2)\n",
    "    noise_df = pd.DataFrame(append_list2)\n",
    "    final_df = pd.concat([cluster_df, noise_df])\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    if visual == True:\n",
    "        labels = final_df.iloc[:,-1:].values.reshape(1,-1)[0]\n",
    "        unique_labels = set(labels)\n",
    "        for i,k in enumerate(unique_labels):\n",
    "            indexlist = list(np.argwhere(labels==k).reshape(1,-1)[0])\n",
    "            sns.clustermap(final_df.iloc[indexlist,2:-1].values,cmap='Reds',col_cluster=True,yticklabels=False,xticklabels=False,figsize=(5,5))\n",
    "            plt.title('trend'+'label='+ str(k))\n",
    "            plt.show()\n",
    "    else:\n",
    "        pass\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1=trend_calc(d_sample, ['SR520-Cal'], min_size=5, normalization='zscore', visual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = pd.read_csv('../example_data/clustering/sample0815.csv')\n",
    "d_model = d_label[d_label['label']!=-1] # 1114.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment of new dataset\n",
    "rt_error = 0.5\n",
    "mz_error = 0.015\n",
    "result = []\n",
    "for row in np.arange(len(d_model)):\n",
    "    overlap = np.where((d_test.iloc[:, 0] - rt_error <=\n",
    "                                    d_model.iloc[row, 0]) & (d_model.iloc[row, 0] <=\n",
    "                                    d_test.iloc[:, 0] + rt_error) & (d_test.iloc[:, 1] - mz_error <=\n",
    "                                    d_model.iloc[row, 1]) & (d_model.iloc[row, 1] <=\n",
    "                                    d_test.iloc[:, 1] + mz_error))\n",
    "    if len(overlap[0]) == 1:\n",
    "        result.append([overlap[0][0], row])\n",
    "    elif len(overlap[0]) > 1:\n",
    "        dist = []\n",
    "        for i in overlap[0]:\n",
    "            dist.append(np.sqrt(((d_test.iloc[i, 0] - d_model.iloc[row, 0])**2) +\n",
    "                                ((d_test.iloc[i, 1] - d_model.iloc[row, 1])**2)))\n",
    "        result.append([overlap[0][np.argmin(dist)], row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling using overlapping features except noises\n",
    "test_index = [i[0] for i in result]\n",
    "model_index = [i[1] for i in result]\n",
    "d_test = d_test.loc[test_index]\n",
    "d_model = d_model.iloc[model_index]\n",
    "data = [d_model, d_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_model = [col for col in d_model.columns if 'SR520-Cal' in col]\n",
    "d_model = d_model[col_model].T\n",
    "d_model.reset_index(inplace=True)\n",
    "d_model = d_model.rename(columns={'index':'dilu_vol'})\n",
    "d_model['dilu_vol'] = d_model['dilu_vol'].apply(lambda x : x.replace('-','_'))\n",
    "d_model['dilu_vol'] = d_model['dilu_vol'].apply(lambda x : float(x.split('_')[-2][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_test = [col for col in d_test.columns if 'SR520_Cal' in col]\n",
    "d_test = d_test[col_test].T\n",
    "d_test.reset_index(inplace=True)\n",
    "d_test = d_test.rename(columns={'index':'dilu_vol'})\n",
    "d_test['dilu_vol'] = d_test['dilu_vol'].apply(lambda x : float(x.split('_')[-2][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = d_model.iloc[: , 1:]\n",
    "y_train = d_model['dilu_vol']\n",
    "X_test = d_test.iloc[: , 1:]\n",
    "y_test = d_test['dilu_vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "#Ref: selflearning/direct-modeling.ipynb\n",
    "#Due to small sample size, maybe consider decision tree or random forest rather than knn\n",
    "#Model all features at one step:\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) #How to deal with the data shape? -- align old data and new data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression() #Colinearity is heavy -- grouping and reduce variable could impact alot\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb161fedd0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8dcHQgJhC/sWYjBEtkQBRxB3cQERxaLW7SpSWuxya73Xay8RFSri1lq1tqK0WJefdQ9LgQt1pS4IDVqcQIhhE8KWQMIaEpLM9/fHnGiAgJBtkpn38/HII3O+50zO5+Qk73xz5jvfY845REQkMjQJdQEiIlJ/FPoiIhFEoS8iEkEU+iIiEUShLyISQaJCXcDxdOzY0SUmJoa6DBGRRmXFihU7nXOdqlrXoEM/MTGRjIyMUJchItKomNk3x1qnyzsiIhFEoS8iEkEU+iIiEUShLyISQRT6IiIR5HtD38xeMLM8M8us1NbezN41sxzvczuv3czsD2a21sy+MrPBlZ4zzts+x8zG1c3hiIjI8ZxIT/9FYOQRbZOA951zycD73jLAFUCy9zERmAHBPxLAFGAoMASYUvGHQkRE6s/3hr5z7p9AwRHNY4CXvMcvAddUan/ZBX0OxJlZN2AE8K5zrsA5Vwi8y9F/SEREIl4g4Hht+SbeW72jTr5+da/pd3HObQPwPnf22nsAmyttl+u1Hav9KGY20cwyzCwjPz+/muWJiDQ+a/P2cePMz0lL9zN35dY62UdtvyPXqmhzx2k/utG5mcBMAJ/Ppzu8iEjYKykrZ8ZH63j2w3W0iG7K49eezvW++DrZV3VDf4eZdXPObfMu3+R57blAz0rbxQNbvfaLjmj/qJr7FhEJG8s3FJCW/hXr8g9w9RnduX90fzq1jqmz/VX38s48oGIEzjhgbqX227xRPGcDe7zLP4uBy82snfcC7uVem4hIRNpTVEpa+lf88PmllJQFeHH8WfzhpkF1GvhwAj19M3uNYC+9o5nlEhyF8yjwpplNADYB13ubLwRGAWuBImA8gHOuwMymAf/ytnvQOXfki8MiImHPOccC/zamzltNwYESJl5wKnddmkxsdP3Mf2kN+cboPp/PaZZNEQkXuYVFPDB3FR+sySO1R1seGZtKSo+2tb4fM1vhnPNVta5BT60sIhIOygOOFz/byBP/yMY5uO/Kftx+TiJRTet/UgSFvohIHcrcsoe0dD/+LXu4uE8npl2TQny72JDVo9AXEakDRYfKeOq9HGZ9soF2sdH88eZBXJnaDbOqRrDXH4W+iEgt+yg7j/vmZJJbeJCbhvRk0sh+tI1tFuqyAIW+iEityd9XwrT5q5m3citJnVry5h3DGNKrfajLOoxCX0SkhpxzvJWRy/SFWRw8VM5dlybzs4uSiIlqGurSjqLQFxGpgfX5+7l3tp/P1xcwJLE9D49NoXfn1qEu65gU+iIi1XCoLMDzS9bxzIdriYlqwiNjU7nB15MmTUL7Qu33UeiLiJykjI0FpKX7ycnbz+jTu/HAVf3p3Lp5qMs6IQp9EZETtOdgKY8vWsOryzbRI64FL9zuY3jfLqEu66Qo9EVEvodzjkWZ25kybxU795cw4bxe/Pdlp9EypvFFaOOrWESkHm3dfZAH5mbyXlYeA7q3Yda4s0iNr/35cuqLQl9EpArlAcfLSzfyu8XZBBxMHtWP8eeGZr6c2qTQFxE5wuqte0lL/4qVuXu48LROPHRNCj3b1998OTc8vxSAN+4YVutfW6EvIuI5eKicp9/P4c8fryeuRTOevnEgV5/RPeTz5dQmhb6ICPBxTj6TZ2eyqaCIH/riuXdUP+Jio+u1hooe/rINBYct12aPX6EvIhFt1/4Spi/IIv3LLfTq2JK//WQo5yR1DHVZdUahLyIRyTnHO19sYfqC1ewvKePO4b35+cW9ad4sdPPlVPTodU1fRKQWbdx5gHtn+/ls3S7OPKUdj4xN5bQuDXe+nNqk0BeRiFFaHmDmP9fzh/dziG7ahIeuSeHmIQkNbr6cuujhV1Doi0hE+GJTIWnv+MnesY8rUroy9eoBdGnTOObLqU0KfREJa/uKS/nt4mxe+fwburZpzp9v83FZ/8Y1X05tUuiLSNhavGo7U+auYse+YsYNS+R/RvShVSOYL0cv5IqInITte4qZMi+Txat20Ldra5679UwG9owLdVknbPW2vXX2tRX6IhI2ygOOV5d9w+OLsiktDzDpir5MOK8XzRrJfDkVPfx9xWWHLevNWSIiR1izfS9p6X6+3LSb85M78tA1KZzSoWWoyzopR/bw66LHr9AXkUatuLScZz7I4fkl62nTohlP3nAG1wzs0Sjny+nfrQ3w3TQMFcu1SaEvIo3Wp2t3Mnm2n427irh2cDyTr+xH+5b1O19Obaq4jJM6dfFhy7VJoS8ijU7BgUNMX5DFO1/kktghlld/PJRze4fPfDl10cOvoNAXkUbDOcecf29h2vws9h4s5RcXJ/HL4ckhnS+nLjTYd+Sa2X8BPwYc4AfGA92A14H2wBfArc65Q2YWA7wMnAnsAm5wzm2syf5FJHJs2lXE5Dl+Ps7ZyaCEOB4Zm0rfrnXXIw5X1R7HZGY9gDsBn3MuBWgK3Ag8BjzpnEsGCoEJ3lMmAIXOud7Ak952IiLHVVoe4Lkl67j8qSV8uWk308YM4O2fnqPAr6aaXt6JAlqYWSkQC2wDhgM3e+tfAqYCM4Ax3mOAt4E/mpk551wNaxCRMLVy824mpfvJ2raXEQO68JurU+jaNvLmy6lN1Q5959wWM/sdsAk4CPwDWAHsds6VeZvlAj28xz2Azd5zy8xsD9AB2Fn565rZRGAiQEJCQnXLE5FGbH9JGb9bnM1LSzfSuXUMz/3HmYxM6RrqssJCtUPfzNoR7L33AnYDbwFXVLFpRU++qkGzR/XynXMzgZkAPp9P/wWIRJj3Vu/g/rmZbN9bzK1nn8I9I/rQunmzUJcVNmpyeedSYINzLh/AzNKBc4A4M4vyevvxwFZv+1ygJ5BrZlFAW6CgBvsXkTCSt7eYqX9fxUL/dvp0ac2fbhnM4IR2oS4r7NQk9DcBZ5tZLMHLO5cAGcCHwHUER/CMA+Z628/zlpd66z/Q9XwRCQQcf1u+iccWraGkLMA9I/rwk/NPJTqqccyX09jU5Jr+MjN7m+CwzDLgS4KXZRYAr5vZQ17bLO8ps4BXzGwtwR7+jTUpXEQav6937CMt3c+Kbwo5J6kD03+QSq+OjWu+nMbGGnJn2+fzuYyMjFCXISK1rLi0nGc/XMuMJetoGRPFfVf259rBjXO+nIbIzFY453xVrdM7ckWkXi1dt4vJs/2s33mAHwzqwX1X9qNDq5hQlxUxFPoiUi92Fx3i4YVZvJmRS0L7WF6ZMITzkzuFuqyIo9AXkTrlnGPeyq1Mm7+awqJSfnphEr+6JJkW0eE1X05jodAXkTqzuaCI++ZksuTrfM6Ib8vLPxpK/+6aPiGUFPoiUuvKygO88OkGnnw3hyYGU67qz23DEmnaRC/UhppCX0Rq1Ve5u0lL97Nq614u7deZB8ek0D2uRajLEo9CX0RqxYGSMn7/7tf89dMNdGwVw4xbBjMypauGYTYwCn0RqbEP1uzg/jmr2LL7ILcMTeDXI/vStoXmy2mIFPoiUm15+4r5zd9Xs+CrbSR3bsXbPx2GL7F9qMuS41Doi8hJCwQcb2Rs5pGFWRSXBrj7stO448IkzZfTCCj0ReSkrM3bz73pfpZvLGBor/Y8PDaVpE6tQl2WnCCFvoickJKycmZ8tI5nP1xHi+imPH7t6Vzvi9cLtY2MQl9EvtfyDQWkpX/FuvwDjBnYnftH96ej5stplBT6InJMe4pKeXRRFq8t30x8uxa8OP4sLurTOdRlSQ0o9EXkKM45Fvi3MXXeagqLDjHxglO569JkYqMVGY2dzqCIHCa3sIgH5q7igzV5pPZoy4vjzyKlR9tQlyW1RKEvIgCUBxwvfraRJ/6RDcD9o/szbtgpRDXVMMxwotAXETK37CEt3Y9/yx4u7tOJadekEN8uNtRlSR1Q6ItEsKJDZTz1Xg6zPtlAu9ho/njzIK5M7aZhmGFMoS8SoT7KzuO+OZnkFh7kpiE9mTSyH21jNV9OuFPoi0SY/H0lTJu/mnkrt5LUqSVv3jGMIb00X06kUOiLRAjnHG9l5DJ9YRYHD5Vz16XJ/OyiJGKidNvCSKLQF4kA6/P3c+9sP5+vL2BIYnseHptC786tQ12WhIBCXySMHSoL8PySdTzz4VpioprwyNhUbvD1pIluWxixFPoiYSpjYwFp6X5y8vYz+vRuPHBVfzq3bh7qsiTEFPoiYWbPwVIeX7SGV5dtokdcC1643cfwvl1CXZY0EAp9kTDhnGNR5namzFvFzv0lTDivF/992Wm0jNGvuXxHPw0iYWDr7oM8MHcV72XtYED3Nswadxap8ZovR46m0BdpxMoDjleWbuS3i7MJOJg8qh/jz03UfDlyTDUKfTOLA/4CpAAO+BGQDbwBJAIbgR865wot+L7up4FRQBFwu3Pui5rsXySSZW3by6R0Pys37+bC0zrx0DUp9Gyv+XLk+GraHXgaWOSc6wucAWQBk4D3nXPJwPveMsAVQLL3MRGYUcN9i0Skg4fKefT/1jD6mU/ILSji6RsH8uL4sxT4ckKq3dM3szbABcDtAM65Q8AhMxsDXORt9hLwEfC/wBjgZeecAz43szgz6+ac21bt6kUizMc5+UyencmmgiJu8PUkbVRf4mKjQ12WNCI1ubxzKpAP/NXMzgBWAL8CulQEuXNum5lV3FutB7C50vNzvbbDQt/MJhL8T4CEhIQalCcSPnbtL2H6gizSv9zCqR1b8tpPzmZYUodQlyWNUE1CPwoYDPzSObfMzJ7mu0s5VanqLYDuqAbnZgIzAXw+31HrRSKJc453vtjC9AWr2V9Sxp3De/Pzi3vTvJnmy5HqqUno5wK5zrll3vLbBEN/R8VlGzPrBuRV2r5npefHA1trsH+RsLZx5wHune3ns3W78J3SjkfGppLcRfPlSM1UO/Sdc9vNbLOZ9XHOZQOXAKu9j3HAo97nud5T5gH/aWavA0OBPbqeL3K00vIAM/+5nj+8n0N00yZM/0EKN52VoPlypFbUdJz+L4FXzSwaWA+MJzgi6E0zmwBsAq73tl1IcLjmWoJDNsfXcN8iYeeLTYWkveMne8c+RqV2ZcpVA+jSRvPlSO2pUeg75/4N+KpYdUkV2zrgFzXZn0i42ldcym8XZ/PK59/QtU1z/nybj8v6a74cqX16R65IiC1etZ0pc1exY18x44Yl8j8j+tBK8+VIHdFPlkiIbN9TzJR5mSxetYO+XVvz3K1nMrBnXKjLkjCn0BepZ+UBx6vLvuHxRdmUlgeYdEVfJpzXi2aaL0fqgUJfpB6t2b6XtHQ/X27azfnJHXnomhRO6dAy1GVJBFHoi9SD4tJynvkgh+eXrKdNi2Y8ecMZXDOwB8F5CEXqj0JfpI59unYnk2f72biriGsHxzP5yn60b6n5ciQ0FPoidaTwwCEeWpDFO1/kktghlld/PJRze3cMdVkS4RT6IrXMOcecf29h2vws9h4s5RcXJ/HL4cmaL0caBIW+SC3atKuIyXP8fJyzk0EJcTwyNpW+XduEuiyRbyn0RWpBaXmAWZ9s4Kn3viaqSROmjRnAzUNPoanmy5EGRqEvUkMrN+9mUrqfrG17GTGgC7+5OoWubTVfjjRMCn2RatpfUsbvFmfz0tKNdG4dw3P/cSYjU7qGuiyR41Loi1TDe6t3cP/cTLbvLebWs0/hnhF9aN28WajLEvleCn2Rk5C3t5ipf1/FQv92+nRpzZ9uGczghHahLkvkhCn0RU5AIOD42/JNPLZoDSVlAe4Z0YeJF5yq+XKk0VHoi3yPr3fsIy3dz4pvCjknqQPTf5BKr46aL0caJ4W+yDEUl5bz7IdrmbFkHa1ionji+jMYO1jz5UjjptAXqcLSdbuYPNvP+p0HGDuoB5Ov7EeHVjGhLkukxhT6IpXsLjrEwwuzeDMjl4T2sbwyYQjnJ3cKdVkitUahL0Jwvpx5K7cybf5qCotK+emFSfzqkmRaRGu+HAkvCn2JeJsLirhvTiZLvs7njPi2vPyjofTvrvlyJDwp9CVilZUHeOHTDTz5bg5NDKZc1Z/bhiVqvhwJawp9iUhf5e4mLd3Pqq17ubRfZx4ck0L3uBahLkukzin0JaIcKCnj9+9+zV8/3UDHVjHMuGUwI1O6ahimRAyFvkSMD9fkcd+cTLbsPsgtQxP49ci+tG2h+XIksij0pdFKnboYAP/UEcfdLm9fMQ/+fTXzv9pGcudWvP3TYfgS29dHiSINjkJfwlYg4HgzYzMPL8yiuDTA3Zedxh0XJhEdpflyJHIp9KXRqejh7ysuO2y5co9/bd5+7k33s3xjAUN7tefhsakkdWpV/8WKNDAKfQkrJWXlzPhoHc9+uI4W0U15/NrTud4XrxdqRTwKfWl0Knr0SWkLDltevqGAtPSvWJd/gDEDu3P/6P501Hw5IoepceibWVMgA9jinBttZr2A14H2wBfArc65Q2YWA7wMnAnsAm5wzm2s6f5F9hSV8uiiLF5bvpn4di14cfxZXNSnc6jLEmmQaqOn/ysgC6h43/pjwJPOudfN7DlgAjDD+1zonOttZjd6291QC/uXCHPD80sBKHfBZd/0dyktd0y84FTuujSZ2Gj9AytyLDUaxmBm8cCVwF+8ZQOGA297m7wEXOM9HuMt462/xHShVaqppLT828fRTZuQ0r0N947qp8AX+R41/Q15Cvg10Npb7gDsds6Vecu5QA/vcQ9gM4BzrszM9njb76z8Bc1sIjARICEhoYblSbgpDzguH9CVJ/6RTROD+HaxfHD3hUTptoUiJ6TaoW9mo4E859wKM7uoormKTd0JrPuuwbmZwEwAn8931HqJXJlb9pCW7se/ZQ/D+3amYH8JMc2aKvBFTkJNevrnAleb2SigOcFr+k8BcWYW5fX244Gt3va5QE8g18yigLZAQQ32LxGi6FAZT72Xw6xPNtAuNpo/3jyIK1O7aRimSDVUO/Sdc2lAGoDX0/8f59wtZvYWcB3BETzjgLneU+Z5y0u99R8459STl+P6KDs4X05u4UFuGpLApJF9aRsbnC+n4gXdN+4YFsoSRRqVunjV63+B183sIeBLYJbXPgt4xczWEuzh31gH+5Ywkb+vhGnzVzNv5VaSOrXkzTuGMaSX5ssRqSlryJ1tn8/nMjIyQl2G1CPnHG9l5DJ9YRYHD5Xz84uT+NlFScREfXfbwooe/rINwauDQ70/BurxiwSZ2QrnnK+qdRrfJg3G+vz93Dvbz+frCxiSGJwvp3dnzZcjUpsU+hJyh8oCPL9kHc98uJbmUU14dGwqP/T1pMkxblu4etve4y6LyLEp9CWkVnxTwKR3/OTk7Wf06d144Kr+dG7dPNRliYQthb6ExN7iUh5ftIb/9/kmesS14IXbfQzv2+WEnlsxwdqJ3kRFRL6j0Jd65ZxjUeZ2psxbxc79JUw4rxf/fdlptIzRj6JIfdBvmtSbrbsP8sDcVbyXtYMB3dswa9xZpMa3rfbXUw9f5OQp9KXOlQccryzdyG8XZxNwMHlUP8afm6jpE0RCQKEvdSpr214mpftZuXk3F57WiYeuSaFn+9hQlyUSsRT6UicOHirn6fdz+PPH64lr0YynbxzI1Wd013w5IiGm0Jda93FOPpNnZ7KpoIgbfD1JG9WXuNjoUJclIij0pRbt2l/C9AVZpH+5hVM7tuS1n5zNsKQOoS5LRCpR6EuNOed454stTF+wmv0lZdw5vDc/v7g3zZs1/f4ni0i9UuhLjWzceYB7Z/v5bN0ufKe045GxqSR3af39TxSRkFDoS7WUlgeY+c/1/OH9HKKbNmH6D1K46ayEY86XIyINg0JfTtoXmwpJe8dP9o59jErtypSrBtCljebLEWkMFPpywvYVl/Lbxdm88vk3dG3TnD/f5uOy/ic2X46INAwKfTkhi1dtZ8rcVezYV8zt5yRy9+V9aKX5ckQaHf3WynFt31PMlHmZLF61g37d2vDcrWcysGdcqMsSkWpS6EuVygOOV5d9w+OLsikLBJh0RV8mnNeLZpovR6RRU+jLUdZs30taup8vN+3m/OSOTL8mlYQOmi9HJBwo9OVbxaXlPPNBDs8vWU+bFs146oaBjBmo+XJEwolCXwD4bO1O7p3tZ+OuIq47M57Jo/rRrqXmyxEJNwr9CFd44BDTF2bx9opcEjvE8uqPh3Ju746hLktE6ohCP0I555jz7y1Mm5/F3oOl/OLiJH45PFnz5YiEOYV+BNq0q4jJc/x8nLOTQQlxPDI2lb5d24S6LBGpBwr9CFJaHmDWJxt46r2viWrShGljBnDz0FNoqvlyRCKGQj9CrNy8m0npfrK27WXEgC785uoUurbVfDkikUahH+b2l5Txu8XZvLR0I51bx/Dcf5zJyJSuoS5LREJEoR/G3lu9g/vnZrJ9bzG3nn0K94zoQ+vmzUJdloiEULVD38x6Ai8DXYEAMNM597SZtQfeABKBjcAPnXOFFnyHz9PAKKAIuN0590XNypeq5O0tZurfV7HQv50+XVrzp1sGMzihXajLEpEGoCY9/TLgbufcF2bWGlhhZu8CtwPvO+ceNbNJwCTgf4ErgGTvYygww/sstSQQcPxt+SYeW7SGkrIA94zow8QLTtV8OSLyrWqHvnNuG7DNe7zPzLKAHsAY4CJvs5eAjwiG/hjgZeecAz43szgz6+Z9Hamhr3fsIy3dz4pvCjknqQPTf5BKr44tQ12WiDQwtXJN38wSgUHAMqBLRZA757aZWWdvsx7A5kpPy/XaDgt9M5sITARISEiojfLCWnFpOc9+uJYZS9bRKiaKJ64/g7GDe2i+HBGpUo1D38xaAe8Adznn9h4nbKpa4Y5qcG4mMBPA5/MdtT5SpE5dDIB/6ohjbrN03S4mz/azfucBxg7qweQr+9GhVUx9lSgijVCNQt/MmhEM/Fedc+le846KyzZm1g3I89pzgZ6Vnh4PbK3J/iPV7qJDPLwwizczckloH8srE4ZwfnKnUJclIo1ATUbvGDALyHLO/b7SqnnAOOBR7/PcSu3/aWavE3wBd4+u5x+tooe/r7jssGX/1BE455i3civT5q+msKiUn12UxJ3Dk2kRrflyROTE1KSnfy5wK+A3s397bfcSDPs3zWwCsAm43lu3kOBwzbUEh2yOr8G+I87mgiLum5PJkq/zOaNnHC//KJX+3TVfjoicHAsOpmmYfD6fy8jICHUZIZE4aQEAa6dfwV8/3cjv3/2aJgb3jOjDrcMSNV+OiByTma1wzvmqWqd35DYwFZdzKpx23/8RcHBpvy48OGYA3eNahKgyEQkHCv0GpuJafoWA94/Yn287U8MwRaTGFPoNTItmTSguDXw7lrVVTFPMTIEvIrVCod9A5O0r5sG/r+ZgaYDkzq3IydsPQOZvRoa4MhEJJ5qUJcQCAcfryzdx6RNL+MeqHdx92WksuPN8WjePonVz/U0WkdqlVAmhtXn7uTfdz/KNBQzt1Z6Hx6aS1KkVcPx34oqIVJdCPwRKysqZ8dE6nv1wHS2im/L4tadzvS9e1+1FpM4p9OvZ8g0FpKV/xbr8A4wZ2J37R/eno+bLEZF6otCvJ3uKSnl0URavLd9MfLsWvDj+LC7q0/n7nygiUosU+nXMOccC/zamzltNYdEhJl5wKnddmkxstL71IlL/lDx1KLewiAfmruKDNXmk9mjLi+PPIqVH21CXJSIRTKFfB8oDjhc/28gT/8gG4P7R/Rk37BSidNtCEQkxhX4ty9yyh7R0P/4texjetzMPjhlAfLvYUJclIgIo9GtN0aEynnovh1mfbKBdbDR/vHkQV6Z20zBMEWlQFPrf40RuW/hRdh73zckkt/AgNw1JYNLIvrSNbVZfJYqInDCFfg3k7yth2vzVzFu5laROLXnzjmEM6dU+1GWJiByTQv8Yvu+2hW9l5DJ9YRYHD5Vz16XJ/OyiJGKidNtCEWnYFPonaX3+fu6d7efz9QUMSQzOl9O7c6tQlyUickIU+sfQv1vw/rPLNhQA0Ldra7btLmbk0x/TPKoJj45N5Ye+njTRbQtFpBFR6B/D6m17D1te8U0hAQejT+/GA1f1p3Pr5iGqTESk+hT6x1BUUkble8YHXPDmA3+8eXDIahIRqSmFfhWcczSLakJJaeDbtorbFoqINGYRGfo3PL8UgDfuGHbUuq27D/LA3FUUlwYY0L0NWVv3YqbbFopIeIjI0M/YWHBUW3nA8crSjfx2cTYBB5NH9WP8uYkMmvZu/RcoIlJHIir0K3r45e7w5alXD2BSup+Vm3dz4WmdeOiaFHq2D86Xo9sWikg4iajQP7KH/68NBThg9DOfENeiGU/fOJCrz+iua/ciErYiIvQr3k17pIqXaa8bHE/aqL7ExUbXX1EiIiEQEaFfVFL27ePKwzAhOAzzsetOr9+CRERCJKxDv6KHX+6qXq9hmCISaeo99M1sJPA00BT4i3Pu0brYT1LaAsodNK0i05uAhmGKSESq1/v3mVlT4E/AFUB/4CYz61+X++wW1+Lbx4kdYhmS2I6WzaOIjQnrf3JERKpU38k3BFjrnFsPYGavA2OA1bW1g6S0BcB3l3RyCw9+u+6jey6urd2IiDRK9X2n7h7A5krLuV5brTryxdoKqVMXH3Mkj4hIJKjv0K/qVdPDItrMJppZhpll5Ofnn/QO1j1yJV9Pv+LbHVW+pl9UUnbYSB4RkUhT36GfC/SstBwPbK28gXNupnPO55zzderUqVo7iWra5Nu/JL7E725f6Etsf9iyiEikqe/Q/xeQbGa9zCwauBGYVxc7amrBjzfuGHbY46omWRMRiRT1+kKuc67MzP4TWExwyOYLzrlVtbmPI8fmVyyrhy8iEoJx+s65hcDCuvr6R16zr1hWD19EJAzfkVvRo6+4t616+CIi3wm70K/o0VeM11cPX0TkO2EX+hXUwxcROVrYhr56+CIiR6vvIZsiIhJCCn0RkQii0BcRiSAKfYUe2xwAAAR1SURBVBGRCKLQFxGJIAp9EZEIYu5Yk883AGaWD3xTgy/REdhZS+U0BpF2vKBjjhQ65pNzinOuymmKG3To15SZZTjnfKGuo75E2vGCjjlS6Jhrjy7viIhEEIW+iEgECffQnxnqAupZpB0v6JgjhY65loT1NX0RETlcuPf0RUSkEoW+iEgECcvQN7ORZpZtZmvNbFKo66ktZtbTzD40sywzW2Vmv/La25vZu2aW431u57Wbmf3B+z58ZWaDQ3sE1WNmTc3sSzOb7y33MrNl3vG+YWbRXnuMt7zWW58Yyrqry8zizOxtM1vjnethEXCO/8v7mc40s9fMrHm4nWcze8HM8swss1LbSZ9XMxvnbZ9jZuNOto6wC30zawr8CbgC6A/cZGb9Q1tVrSkD7nbO9QPOBn7hHdsk4H3nXDLwvrcMwe9BsvcxEZhR/yXXil8BWZWWHwOe9I63EJjgtU8ACp1zvYEnve0ao6eBRc65vsAZBI89bM+xmfUA7gR8zrkUoClwI+F3nl8ERh7RdlLn1czaA1OAocAQYErFH4oT5pwLqw9gGLC40nIakBbquuroWOcClwHZQDevrRuQ7T1+Hrip0vbfbtdYPoB475dhODAfMILvUow68nwDi4Fh3uMobzsL9TGc5PG2ATYcWXeYn+MewGagvXfe5gMjwvE8A4lAZnXPK3AT8Hyl9sO2O5GPsOvp890PUIVcry2seP/SDgKWAV2cc9sAvM+dvc3C4XvxFPBrIOAtdwB2O+fKvOXKx/Tt8Xrr93jbNyanAvnAX71LWn8xs5aE8Tl2zm0BfgdsArYRPG8rCO/zXOFkz2uNz3c4hr5V0RZW41LNrBXwDnCXc27v8Tatoq3RfC/MbDSQ55xbUbm5ik3dCaxrLKKAwcAM59wg4ADf/ctflUZ/zN7liTFAL6A70JLg5Y0jhdN5/j7HOsYaH3s4hn4u0LPScjywNUS11Doza0Yw8F91zqV7zTvMrJu3vhuQ57U39u/FucDVZrYReJ3gJZ6ngDgzq7i/c+Vj+vZ4vfVtgYL6LLgW5AK5zrll3vLbBP8IhOs5BrgU2OCcy3fOlQLpwDmE93mucLLntcbnOxxD/19AsvfKfzTBF4TmhbimWmFmBswCspxzv6+0ah5Q8Sr+OILX+ivab/NGApwN7Kn4V7IxcM6lOefinXOJBM/jB865W4APgeu8zY483orvw3Xe9o2qB+ic2w5sNrM+XtMlwGrC9Bx7NgFnm1ms9zNeccxhe54rOdnzuhi43Mzaef8hXe61nbhQv7BRRy+WjAK+BtYBk0NdTy0e13kE/5X7Cvi39zGK4PXM94Ec73N7b3sjOJJpHeAnODoi5MdRzWO/CJjvPT4VWA6sBd4CYrz25t7yWm/9qaGuu5rHOhDI8M7zHKBduJ9j4DfAGiATeAWICbfzDLxG8DWLUoI99gnVOa/Aj7xjXwuMP9k6NA2DiEgECcfLOyIicgwKfRGRCKLQFxGJIAp9EZEIotAXEYkgCn0RkQii0BcRiSD/H3PlNd+HyI5wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_pred,marker='+')\n",
    "plt.plot([0,1000],[0,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|x1 0|x2 1|x3 0|x4 1|x5 1|y|\n",
    "|---|---|---|---|---|---|\n",
    "|1|2|3|5|6|dilution|\n",
    "|1|2|3|5|6|dilution|\n",
    "|1|2|3|5|6|dilution|\n",
    "|1|2|3|5|6|dilution|\n",
    "|1|2|3|5|6|dilution|\n",
    "|1|2|3|5|6|dilution|\n",
    "|5|5|8|10|100|unknown dilution|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster 0 : 1000 features\n",
    "\n",
    "cluster 1: 1000features \n",
    "\n",
    "2: 1000\n",
    "    \n",
    "1. build models on individual clusters: model0 from cluster0 1000 features, model1 from c1 1000features\n",
    "y = ax1+bx2+c\n",
    "y = ax1+blog(x1)+cx1^2+dx2+ --> simplified one\n",
    "\n",
    "2. build models iteratively: randomly pick 50 features from each of clusters, 50 * 3 = 150 features --> model1 --> repeat n times --> \n",
    "\n",
    "3. select representative features:  --> reduce feature numbers in each clusters\n",
    "     1. exclude outliers, 25%-5/50%-10/75%-5 (intensity) features for each cluster\n",
    "     2. calculate the general trend of your cluster and select features base on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-e93aad92a2e9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-e93aad92a2e9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pretreat dataset -- realignment, data clean, etc.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def function(dataset, cluster_algorithm=True, model_method='OLS,RF,etc.', report=True, *model_param):\n",
    "    #All the data inputed should be in the same shape\n",
    "    pretreat dataset -- realignment, data clean, etc.\n",
    "    split dataset into train and test\n",
    "    if use cluster information\n",
    "    \n",
    "    train model\n",
    "    test model\n",
    "    \n",
    "    if generate report -- RSE,loss function\n",
    "    return model\n",
    "\n",
    "the model should be able to use later use model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small data solution:\n",
    "1. use simple model -- OLS, rf/dt\n",
    "2. emsemble method -- combine models from different clusters\n",
    "    1. for instance, seperately build model on n clusters and combine the prediction result at the end\n",
    "    2. further, do the iterative modeling -- take n features out from each cluster, build model, merge result, repeat the process\n",
    "3. use less features for modeling -- only use the features that is representative for the clusters\n",
    "\n",
    "this is especially useful in our case as most of the features within the same cluster should have strong collinearity\n",
    "    \n",
    "    strategy to reduce features in clusters:\n",
    "    0. before reduction, need to verify the cluster is correctly seperated\n",
    "    1. select features most close to the average (normalized average)\n",
    "    2. select features at lower/upper/25%/50%/75% boundaries\n",
    "    3. select features with highest intensity/lowest intensity\n",
    "    \n",
    "<font color = 'red'>4. get confidence interval rather than only a solid prediction result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9395012567181343\n"
     ]
    }
   ],
   "source": [
    "model1  = BaggingRegressor(base_estimator=SVC(),\n",
    "...                         n_estimators=1000, random_state=0).fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "print(\"Accuracy:\",model1.score(X_test,y_test)) #How to deal with the data shape? -- align old data and new data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model1  = BaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
    "...                         n_estimators=1000, random_state=0).fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) #How to deal with the data shape? -- align old data and new data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) #How to deal with the data shape? -- align old data and new data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what confidence level would you like to test? 90\n",
      "your confidence level is 90 +/- 18.71%\n"
     ]
    }
   ],
   "source": [
    "# confidence interval: Z = 1.64(90%), 1.96(95%), 2.33(98%), 2/58(99%)\n",
    "confidence_interval = int(input(\"what confidence level would you like to test? \"))\n",
    "z_value = {90:1.64,95:1.96,98:2.33,99:2.58}\n",
    "n = 10\n",
    "interval = z_value[confidence_interval] * ((metrics.accuracy_score(y_test,y_pred) * (1-metrics.accuracy_score(y_test,y_pred)))/n)**(1/2)\n",
    "new_interval = format(interval*100, '.2f')\n",
    "print(\"your confidence level is \" + str(confidence_interval) + \" +/- \" + str(new_interval) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (400,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-94047d6739f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m ax.plot(np.arange(n_estimators) + 1, dt_err,\n\u001b[1;32m     36\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Discrete AdaBoost Test Error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         color='red')\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m#ax.plot(np.arange(n_estimators) + 1, ada_discrete_err_train,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#        label='Discrete AdaBoost Train Error',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \"\"\"\n\u001b[1;32m   1664\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (400,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization\n",
    "print(__doc__)\n",
    "\n",
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>,\n",
    "#         Noel Dawe <noel.dawe@gmail.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "n_estimators = 400\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = 1.\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "model_err = 1.0 - model.score(X_test, y_test)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_err = 1.0 - dt.score(X_test, y_test)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [model_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "\n",
    "ada_real_err_train = np.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_real.staged_predict(X_train)):\n",
    "    ada_real_err_train[i] = zero_one_loss(y_pred, y_train)\n",
    "\n",
    "ax.plot(np.arange(n_estimators) + 1, dt_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "#ax.plot(np.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "#        label='Discrete AdaBoost Train Error',\n",
    "#        color='blue')\n",
    "#ax.plot(np.arange(n_estimators) + 1, ada_real_err,\n",
    "#        label='Real AdaBoost Test Error',\n",
    "#        color='orange')\n",
    "#ax.plot(np.arange(n_estimators) + 1, ada_real_err_train,\n",
    "#        label='Real AdaBoost Train Error',\n",
    "#        color='green') \n",
    "\n",
    "ax.set_ylim((0.0, 0.5))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
